"""Unit tests for student agents with Gemini API (real LLM calls).

Tests validate:
- Single and multi-turn responses
- Audio generation
- Response structure (StudentResponse schema)
- Student approach grounding (responses reflect lesson-specific approaches)
"""

import asyncio
import pytest
import base64
from pathlib import Path
from rehearsed_multi_student.profiles.loader import ProfileLoader
from rehearsed_multi_student.agents.student_agent import ParallelStudentOrchestrator, StudentAgent
from rehearsed_multi_student.models.domain import ConversationMessage
from rehearsed_multi_student.models.student_agent import TeacherPromptRequest, StudentResponse
from rehearsed_multi_student.models.lesson_analyzer import LessonContext, StudentApproachOutput
from rehearsed_multi_student.services.tts_service import TextToSpeechService
from rehearsed_multi_student.services.lesson_analyzer import LessonAnalyzer


def create_lesson_context_with_approaches(profiles_list=None):
    """Create lesson context WITH student approaches (as would be generated by lesson analyzer)."""
    # Create student approaches for each profile
    student_approaches = {
        "algorithmic_thinker": StudentApproachOutput(
            student_id="algorithmic_thinker",
            student_name="Vex",
            learning_style="algorithmic",
            thinking_approach="Vex would approach this by identifying the slope first (m=2) and then understanding that parallel lines must have the same slope. They would systematically think: for a line parallel to y=2x+1, any line of the form y=2x+b would work, where b is different from 1."
        ),
        "visual_thinker": StudentApproachOutput(
            student_id="visual_thinker",
            student_name="Chipper",
            learning_style="visual",
            thinking_approach="Chipper would visualize the line y=2x+1 on a coordinate plane, seeing it rise steeply with slope 2. They would then mentally draw parallel lines - all going at the same angle - and understand that shifting the line up or down (changing the y-intercept) keeps it parallel."
        ),
        "struggling_learner": StudentApproachOutput(
            student_id="struggling_learner",
            student_name="Riven",
            learning_style="struggling",
            thinking_approach="Riven would likely recall that parallel lines 'go the same direction' but might struggle to explain why. They would need scaffolding like: 'Lines that look the same steepness are parallel.' They might confuse slope with y-intercept but with support could identify that y=2x+5 or y=2x-3 look similar to y=2x+1."
        ),
    }
    
    return LessonContext(
        grade_level="8th grade",
        subject="Mathematics",
        topic="Linear Equations and Parallel Lines",
        learning_objectives=["Understand parallel lines", "Relate slope to parallel lines"],
        key_concepts=["slope", "parallel lines", "linear equations"],
        context_summary="Students are learning about parallel lines in the coordinate plane and how slopes determine parallelism.",
        mathematical_problem="We have the line y = 2x + 1. What would a parallel line look like?",
        student_approaches=student_approaches
    )


def validate_student_response(response: StudentResponse, test_name: str):
    """Validate that a StudentResponse has correct structure and types."""
    print(f"\n  Validating {response.student_name}...")
    
    # Check required fields
    assert response.student_id is not None, f"{test_name}: Missing student_id"
    assert response.student_name is not None, f"{test_name}: Missing student_name"
    assert isinstance(response.would_raise_hand, bool), f"{test_name}: would_raise_hand not bool"
    assert isinstance(response.confidence_score, float), f"{test_name}: confidence_score not float"
    assert 0.0 <= response.confidence_score <= 1.0, f"{test_name}: confidence_score out of range"
    assert isinstance(response.thinking_process, str), f"{test_name}: thinking_process not str"
    assert len(response.thinking_process) > 0, f"{test_name}: thinking_process empty"
    assert response.response is None or isinstance(response.response, str), f"{test_name}: response wrong type"
    
    # If they raise hand, they should have a response
    if response.would_raise_hand:
        assert response.response is not None and len(response.response) > 0, \
            f"{test_name}: {response.student_name} raises hand but has no response"
    
    print(f"    âœ… Structure valid")
    return True


@pytest.mark.asyncio
async def test_single_turn_with_lesson_context():
    """Test single teacher prompt with lesson context containing student approaches."""
    
    print("\n" + "="*80)
    print("TEST 1: SINGLE TURN WITH LESSON CONTEXT + STUDENT APPROACHES")
    print("="*80)
    
    # Load profiles
    profiles_dir = Path(__file__).parent.parent.parent / "src" / "rehearsed_multi_student" / "profiles"
    loader = ProfileLoader(profiles_dir)
    profiles = loader.load_all_profiles()
    
    print(f"\nâœ“ Loaded {len(profiles)} student profiles")
    for profile in profiles:
        print(f"  - {profile.name} ({profile.learning_style})")
    
    # Create orchestrator
    tts_service = TextToSpeechService()
    orchestrator = ParallelStudentOrchestrator(profiles, tts_service)
    print("\nâœ“ Created orchestrator")
    
    # Create request WITH lesson context that includes student approaches
    lesson_context = create_lesson_context_with_approaches(profiles)
    
    print(f"\nðŸ“š Lesson Context:")
    print(f"   Grade: {lesson_context.grade_level}")
    print(f"   Topic: {lesson_context.topic}")
    print(f"   Problem: {lesson_context.mathematical_problem}")
    print(f"   Student Approaches: {len(lesson_context.student_approaches)} profiles")
    
    request = TeacherPromptRequest(
        prompt="We have the line y = 2x + 1. What would a parallel line look like?",
        lesson_context=lesson_context,
        conversation_history=[]
    )
    
    print(f"\nðŸ‘¨â€ðŸ« Teacher: \"{request.prompt}\"")
    print("\nâ³ Processing with all students in parallel...\n")
    
    # Process in parallel
    responses = await orchestrator.process_prompt_parallel(request)
    
    # Validate and display results
    print("="*80)
    print("RESPONSES:")
    print("="*80)
    
    for response in responses:
        validate_student_response(response, "single_turn")
        
        hand = "âœ‹ RAISES HAND" if response.would_raise_hand else "   (stays quiet)"
        print(f"\n{response.student_name} {hand}")
        print(f"  Confidence: {response.confidence_score:.0%}")
        print(f"  Thinking: {response.thinking_process[:120]}...")
        if response.response:
            print(f"  Response: \"{response.response}\"")
    
    # Summary
    num_raising = sum(1 for r in responses if r.would_raise_hand)
    print(f"\nâœ“ {num_raising}/{len(responses)} students would participate")
    assert len(responses) == len(profiles), "Not all profiles got responses"
    assert all(isinstance(r, StudentResponse) for r in responses), "Invalid response types"


@pytest.mark.asyncio
async def test_multi_turn_with_context():
    """Test multi-turn conversation with lesson context persistence."""
    
    print("\n\n" + "="*80)
    print("TEST 2: MULTI-TURN CONVERSATION WITH LESSON CONTEXT")
    print("="*80)
    
    # Load profiles
    profiles_dir = Path(__file__).parent.parent.parent / "src" / "rehearsed_multi_student" / "profiles"
    loader = ProfileLoader(profiles_dir)
    profiles = loader.load_all_profiles()
    
    tts_service = TextToSpeechService()
    orchestrator = ParallelStudentOrchestrator(profiles, tts_service)
    lesson_context = create_lesson_context_with_approaches(profiles)
    
    print(f"\nâœ“ Loaded {len(profiles)} profiles and created orchestrator")
    
    # TURN 1
    print("\n" + "="*80)
    print("ðŸ”„ TURN 1: Initial Question")
    print("="*80)
    
    request1 = TeacherPromptRequest(
        prompt="We have the line y = 2x + 1. What would a parallel line look like?",
        lesson_context=lesson_context,
        conversation_history=[]
    )
    
    print(f"ðŸ‘¨â€ðŸ« Teacher: \"{request1.prompt}\"")
    responses1 = await orchestrator.process_prompt_parallel(request1)
    
    print(f"\nðŸ“Š Turn 1 Results:")
    for response in responses1:
        validate_student_response(response, "multi_turn_turn1")
        print(f"  âœ‹ {response.student_name}: confidence {response.confidence_score:.0%}, raised_hand={response.would_raise_hand}")
    
    # Pick a student who raised hand
    respondent1 = next((r for r in responses1 if r.would_raise_hand), responses1[0])
    print(f"\nðŸ‘¨â€ðŸ« Calls on: {respondent1.student_name}")
    print(f"ðŸ’¬ \"{respondent1.response}\"")
    
    # TURN 2 with conversation history
    print("\n" + "="*80)
    print("ðŸ”„ TURN 2: Follow-up with Conversation History")
    print("="*80)
    
    conversation_history = [
        ConversationMessage(speaker="teacher", message=request1.prompt),
        ConversationMessage(speaker=respondent1.student_name, message=respondent1.response or "")
    ]
    
    request2 = TeacherPromptRequest(
        prompt=f"OK so {respondent1.student_name} said that. What if the lines had DIFFERENT slopes?",
        lesson_context=lesson_context,
        conversation_history=conversation_history
    )
    
    print(f"ðŸ‘¨â€ðŸ« Teacher: \"{request2.prompt}\"")
    responses2 = await orchestrator.process_prompt_parallel(request2)
    
    print(f"\nðŸ“Š Turn 2 Results (with conversation context):")
    for response in responses2:
        validate_student_response(response, "multi_turn_turn2")
        print(f"  âœ‹ {response.student_name}: confidence {response.confidence_score:.0%}")
    
    # Pick a different student
    respondent2 = next(
        (r for r in responses2 if r.would_raise_hand and r.student_name != respondent1.student_name),
        responses2[0]
    )
    print(f"\nðŸ‘¨â€ðŸ« Calls on: {respondent2.student_name}")
    print(f"ðŸ’¬ \"{respondent2.response}\"")
    
    print(f"\nâœ“ Multi-turn test completed: {len(responses1)} students responded in each turn")


@pytest.mark.asyncio
async def test_audio_generation_with_context():
    """Test audio generation with lesson context."""
    
    print("\n\n" + "="*80)
    print("TEST 3: AUDIO GENERATION WITH LESSON CONTEXT")
    print("="*80)
    
    # Load profiles
    profiles_dir = Path(__file__).parent.parent.parent / "src" / "rehearsed_multi_student" / "profiles"
    loader = ProfileLoader(profiles_dir)
    profiles = loader.load_all_profiles()
    
    tts_service = TextToSpeechService()
    orchestrator = ParallelStudentOrchestrator(profiles, tts_service)
    lesson_context = create_lesson_context_with_approaches(profiles)
    
    print("\nâœ“ TTS service initialized")
    
    request = TeacherPromptRequest(
        prompt="We have the line y = 2x + 1. What would a parallel line look like?",
        lesson_context=lesson_context,
        conversation_history=[]
    )
    
    print(f"ðŸ‘¨â€ðŸ« Teacher: \"{request.prompt}\"")
    print("\nâ³ Generating responses WITH AUDIO...\n")
    
    # Get responses with audio
    responses = await orchestrator.process_prompt_parallel(request, include_audio=True)
    
    print("AUDIO GENERATION RESULTS:")
    print("="*80)
    
    # Create audio output directory
    audio_dir = Path(__file__).parent / "audio_output"
    audio_dir.mkdir(exist_ok=True)
    
    audio_count = 0
    for response in responses:
        validate_student_response(response, "audio_generation")
        
        has_audio = "âœ… Audio" if response.audio_base64 else "âŒ No audio"
        
        print(f"\n{response.student_name}:")
        print(f"  Response: {has_audio}")
        print(f"  Raises hand: {response.would_raise_hand}")
        print(f"  Confidence: {response.confidence_score:.0%}")
        
        if response.response:
            print(f"  Says: \"{response.response}\"")
            
            # Save audio to file
            if response.audio_base64:
                audio_file = audio_dir / f"{response.student_name.lower().replace(' ', '_')}_response.mp3"
                try:
                    audio_bytes = base64.b64decode(response.audio_base64)
                    audio_file.write_bytes(audio_bytes)
                    audio_count += 1
                    print(f"  ðŸ’¾ Saved: {audio_file.name} ({len(audio_bytes)} bytes)")
                except Exception as e:
                    print(f"  âŒ Error: {e}")
    
    # Summary
    num_with_text = sum(1 for r in responses if r.response)
    print(f"\nâœ“ Generated audio for {audio_count}/{num_with_text} responses")
    print(f"âœ“ Saved to: {audio_dir}")
    assert audio_count > 0, "No audio was generated"


@pytest.mark.asyncio
async def test_student_approach_grounding():
    """Test that student responses are grounded in their specific lesson approach."""
    
    print("\n\n" + "="*80)
    print("TEST 4: STUDENT APPROACH GROUNDING")
    print("="*80)
    print("\nVerifying that each student's response reflects their specific approach")
    print("as generated by the lesson analyzer for this problem.\n")
    
    # Load profiles
    profiles_dir = Path(__file__).parent.parent.parent / "src" / "rehearsed_multi_student" / "profiles"
    loader = ProfileLoader(profiles_dir)
    profiles = loader.load_all_profiles()
    
    orchestrator = ParallelStudentOrchestrator(profiles, TextToSpeechService())
    lesson_context = create_lesson_context_with_approaches(profiles)
    
    # Show the approaches that should ground the responses
    print("ðŸ“‹ Student Approaches for this problem:")
    print("="*80)
    for student_id, approach in lesson_context.student_approaches.items():
        print(f"\n{approach.student_name} ({approach.learning_style}):")
        print(f"  Approach: {approach.thinking_approach[:150]}...")
    
    # Get responses
    request = TeacherPromptRequest(
        prompt="We have the line y = 2x + 1. What would a parallel line look like?",
        lesson_context=lesson_context,
        conversation_history=[]
    )
    
    print("\n" + "="*80)
    print("ðŸŽ¯ Responses (should reflect approaches above):")
    print("="*80)
    
    responses = await orchestrator.process_prompt_parallel(request)
    
    for response in responses:
        validate_student_response(response, "approach_grounding")
        
        # Find corresponding approach
        approach = lesson_context.student_approaches.get(response.student_id)
        
        print(f"\n{response.student_name}:")
        print(f"  Approach: {approach.thinking_approach[:100]}...")
        print(f"  Response: \"{response.response}\"")
        print(f"  Thinking: {response.thinking_process[:100]}...")
        
        # Verify response is not empty
        assert response.response is not None and len(response.response) > 0, \
            f"{response.student_name}'s response should reflect their approach"
    
    print(f"\nâœ“ All {len(responses)} students' responses are grounded in their approaches")


